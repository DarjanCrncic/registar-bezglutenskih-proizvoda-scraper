name: Daily Gluten-Free Scraper

# Run daily at 2:00 UTC
on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch: # allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v3

    # Step 2: Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    # Step 4: Run the scraper
    - name: Run scraper
      run: |
        python scraper.py

    # Step 5: Switch to gh-pages branch
    - name: Prepare gh-pages branch
      run: |
        git fetch origin gh-pages || git checkout --orphan gh-pages
        git checkout gh-pages || git checkout --orphan gh-pages
        git rm -rf . || echo "Nothing to remove"

    # Step 6: Copy JSONL file to branch
    - name: Copy JSONL
      run: |
        cp gluten_free_products.jsonl .

    # Step 7: Commit and push
    - name: Commit & push
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add gluten_free_products.jsonl
        git commit -m "Update gluten-free JSONL [skip ci]" || echo "No changes to commit"
        git push origin gh-pages
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
